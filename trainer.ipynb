{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.activations import relu, sigmoid, softmax\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 14113848309440722088\n, name: \"/device:XLA_CPU:0\"\ndevice_type: \"XLA_CPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 3504971036894774387\nphysical_device_desc: \"device: XLA_CPU device\"\n, name: \"/device:XLA_GPU:0\"\ndevice_type: \"XLA_GPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 1964454482773568436\nphysical_device_desc: \"device: XLA_GPU device\"\n]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_list = string.ascii_letters+string.digits\n",
    " \n",
    "def encode_to_labels(txt):\n",
    "    # encoding each output word into digits\n",
    "    dig_lst = []\n",
    "    for index, char in enumerate(txt):\n",
    "        try:\n",
    "            dig_lst.append(char_list.index(char))\n",
    "        except:\n",
    "            print(char)\n",
    "        \n",
    "    return dig_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/Downloads/mnt/ramdisk/max/90kDICT32px'\n",
    " \n",
    " \n",
    "training_img = []\n",
    "training_txt = []\n",
    "train_input_length = []\n",
    "train_label_length = []\n",
    "orig_txt = []\n",
    " \n",
    "valid_img = []\n",
    "valid_txt = []\n",
    "valid_input_length = []\n",
    "valid_label_length = []\n",
    "valid_orig_txt = []\n",
    " \n",
    "max_label_len = 0\n",
    " \n",
    "i =1 \n",
    "flag = 0\n",
    " \n",
    "for root, dirnames, filenames in os.walk(path):\n",
    " \n",
    "    for f_name in fnmatch.filter(filenames, '*.jpg'):\n",
    "        img = cv2.cvtColor(cv2.imread(os.path.join(root, f_name)), cv2.COLOR_BGR2GRAY)   \n",
    " \n",
    "        w, h = img.shape\n",
    "        if h > 128 or w > 32:\n",
    "            continue\n",
    "        if w < 32:\n",
    "            add_zeros = np.ones((32-w, h))*255\n",
    "            img = np.concatenate((img, add_zeros))\n",
    " \n",
    "        if h < 128:\n",
    "            add_zeros = np.ones((32, 128-h))*255\n",
    "            img = np.concatenate((img, add_zeros), axis=1)\n",
    "        img = np.expand_dims(img , axis = 2)\n",
    "        \n",
    "        img = img/255.\n",
    "        \n",
    "        txt = f_name.split('_')[1]\n",
    "        \n",
    "        if len(txt) > max_label_len:\n",
    "            max_label_len = len(txt)\n",
    "            \n",
    "           \n",
    "        if i%10 == 0:     \n",
    "            valid_orig_txt.append(txt)   \n",
    "            valid_label_length.append(len(txt))\n",
    "            valid_input_length.append(31)\n",
    "            valid_img.append(img)\n",
    "            valid_txt.append(encode_to_labels(txt))\n",
    "        else:\n",
    "            orig_txt.append(txt)   \n",
    "            train_label_length.append(len(txt))\n",
    "            train_input_length.append(31)\n",
    "            training_img.append(img)\n",
    "            training_txt.append(encode_to_labels(txt)) \n",
    "        \n",
    "        if i == 150000:\n",
    "            flag = 1\n",
    "            break\n",
    "        i+=1\n",
    "    if flag == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_padded_txt = pad_sequences(training_txt, maxlen=max_label_len, padding='post', value = len(char_list))\n",
    "\n",
    "valid_padded_txt = pad_sequences(valid_txt, maxlen=max_label_len, padding='post', value = len(char_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32,128,1))\n",
    " \n",
    "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    " \n",
    "\n",
    "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
    "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    " \n",
    "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
    " \n",
    "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
    "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
    " \n",
    "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
    "batch_norm_5 = BatchNormalization()(conv_5)\n",
    " \n",
    "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
    "batch_norm_6 = BatchNormalization()(conv_6)\n",
    "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    " \n",
    "conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
    " \n",
    "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
    " \n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
    " \n",
    "outputs = Dense(len(char_list)+1, activation = 'softmax')(blstm_2)\n",
    "\n",
    "act_model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 32, 128, 1)]      0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 32, 128, 64)       640       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 16, 64, 64)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 16, 64, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 8, 32, 128)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 8, 32, 256)        295168    \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 8, 32, 256)        590080    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 4, 32, 256)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 4, 32, 512)        1180160   \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 4, 32, 512)        2048      \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 4, 32, 512)        2359808   \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 4, 32, 512)        2048      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 2, 32, 512)        0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 1, 31, 512)        1049088   \n_________________________________________________________________\nlambda (Lambda)              (None, 31, 512)           0         \n_________________________________________________________________\nbidirectional (Bidirectional (None, 31, 256)           656384    \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 31, 256)           394240    \n_________________________________________________________________\ndense (Dense)                (None, 31, 63)            16191     \n=================================================================\nTotal params: 6,619,711\nTrainable params: 6,617,663\nNon-trainable params: 2,048\n_________________________________________________________________\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ec0374706779>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mact_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "act_model.summary()\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From D:\\SoftieS\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:5151: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From D:\\SoftieS\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:5130: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    " \n",
    " \n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    " \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    " \n",
    " \n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "\n",
    "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
    " \n",
    "filepath=\"best_model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img = np.array(training_img)\n",
    "train_input_length = np.array(train_input_length)\n",
    "train_label_length = np.array(train_label_length)\n",
    "\n",
    "valid_img = np.array(valid_img)\n",
    "valid_input_length = np.array(valid_input_length)\n",
    "valid_label_length = np.array(valid_label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 135000 samples, validate on 15000 samples\n",
      "Epoch 1/10\n",
      "134912/135000 [============================>.] - ETA: 4s - loss: 24.2958 \n",
      "Epoch 00001: val_loss improved from inf to 23.12880, saving model to best_model.hdf5\n",
      "135000/135000 [==============================] - 6710s 50ms/sample - loss: 24.2930 - val_loss: 23.1288\n",
      "Epoch 2/10\n",
      "134912/135000 [============================>.] - ETA: 4s - loss: 9.2149 \n",
      "Epoch 00002: val_loss improved from 23.12880 to 5.59027, saving model to best_model.hdf5\n",
      "135000/135000 [==============================] - 6463s 48ms/sample - loss: 9.2127 - val_loss: 5.5903\n",
      "Epoch 3/10\n",
      "134912/135000 [============================>.] - ETA: 4s - loss: 4.3887 \n",
      "Epoch 00003: val_loss improved from 5.59027 to 3.93838, saving model to best_model.hdf5\n",
      "135000/135000 [==============================] - 6403s 47ms/sample - loss: 4.3889 - val_loss: 3.9384\n",
      "Epoch 4/10\n",
      "134912/135000 [============================>.] - ETA: 4s - loss: 3.4442 \n",
      "Epoch 00004: val_loss improved from 3.93838 to 3.47087, saving model to best_model.hdf5\n",
      "135000/135000 [==============================] - 6375s 47ms/sample - loss: 3.4446 - val_loss: 3.4709\n",
      "Epoch 5/10\n",
      "134912/135000 [============================>.] - ETA: 4s - loss: 2.9662 \n",
      "Epoch 00005: val_loss improved from 3.47087 to 3.28433, saving model to best_model.hdf5\n",
      "135000/135000 [==============================] - 7182s 53ms/sample - loss: 2.9672 - val_loss: 3.2843\n",
      "Epoch 6/10\n",
      "134912/135000 [============================>.] - ETA: 5s - loss: 2.6633 \n",
      "Epoch 00006: val_loss improved from 3.28433 to 3.05622, saving model to best_model.hdf5\n",
      "135000/135000 [==============================] - 8032s 59ms/sample - loss: 2.6628 - val_loss: 3.0562\n",
      "Epoch 7/10\n",
      "134912/135000 [============================>.] - ETA: 4s - loss: 2.3956 \n",
      "Epoch 00007: val_loss improved from 3.05622 to 3.04918, saving model to best_model.hdf5\n",
      "135000/135000 [==============================] - 6437s 48ms/sample - loss: 2.3965 - val_loss: 3.0492\n",
      "Epoch 8/10\n",
      "134912/135000 [============================>.] - ETA: 5s - loss: 2.2000 \n",
      "Epoch 00008: val_loss improved from 3.04918 to 2.98661, saving model to best_model.hdf5\n",
      "135000/135000 [==============================] - 8253s 61ms/sample - loss: 2.1999 - val_loss: 2.9866\n",
      "Epoch 9/10\n",
      "134912/135000 [============================>.] - ETA: 4s - loss: 2.0825 \n",
      "Epoch 00009: val_loss did not improve from 2.98661\n",
      "135000/135000 [==============================] - 6543s 48ms/sample - loss: 2.0833 - val_loss: 3.0973\n",
      "Epoch 10/10\n",
      "134912/135000 [============================>.] - ETA: 3s - loss: 1.9581 \n",
      "Epoch 00010: val_loss improved from 2.98661 to 2.95094, saving model to best_model.hdf5\n",
      "135000/135000 [==============================] - 6199s 46ms/sample - loss: 1.9582 - val_loss: 2.9509\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x167dd77a240>"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 10\n",
    "model.fit(x=[training_img, train_padded_txt, train_input_length, train_label_length], y=np.zeros(len(training_img)), batch_size=batch_size, epochs = epochs, validation_data = ([valid_img, valid_padded_txt, valid_input_length, valid_label_length], [np.zeros(len(valid_img))]), verbose = 1, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "original_text =   Expend\npredicted text = Expend\n\noriginal_text =   RAKE\npredicted text = RAKE\n\noriginal_text =   IMAM\npredicted text = Imam\n\noriginal_text =   kraft\npredicted text = krak\n\noriginal_text =   deceleration\npredicted text = deceleration\n\noriginal_text =   FOXHUNTING\npredicted text = FOXHUNTING\n\noriginal_text =   Renaud\npredicted text = Renaud\n\noriginal_text =   Trenchant\npredicted text = Trenchant\n\noriginal_text =   HOD\npredicted text = HOD\n\noriginal_text =   sculpt\npredicted text = sculpt\n\n"
     ]
    }
   ],
   "source": [
    "act_model.load_weights('best_model.hdf5')\n",
    " \n",
    "prediction = act_model.predict(valid_img[:10])\n",
    " \n",
    "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1], greedy=True)[0][0])\n",
    "i = 0\n",
    "for x in out:\n",
    "    print(\"original_text =  \", valid_orig_txt[i])\n",
    "    print(\"predicted text = \", end = '')\n",
    "    for p in x:  \n",
    "        if int(p) != -1:\n",
    "            print(char_list[int(p)], end = '')       \n",
    "    print('\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}